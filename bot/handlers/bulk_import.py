import io
import re
from typing import List, Tuple, cast

from aiogram import Router, F
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.types import Message

from app.core.logging import main_logger
from bot.schemas.channel import AddChannel
from bot.schemas.keyword_schema import KeyWordCreateSchema
from bot.service.user_service import UserService
from bot.utils.depend import get_atomic_db
from bot.models.keyword import KeywordType

router = Router()


class BulkImportChannels(StatesGroup):
    waiting_for_file = State()


class BulkImportKeywords(StatesGroup):
    waiting_for_file = State()


def _is_probably_binary(data: bytes) -> bool:
    """–ì—Ä—É–±–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç NUL –≤ –ø–µ—Ä–≤—ã—Ö –±–∞–π—Ç–∞—Ö –∏–ª–∏ zip-–º–∞–≥–∏–∫."""
    head = data[:4096]
    if b"\x00" in head:
        return True
    # xlsx/docx/pdf/zip
    if head.startswith(b"PK\x03\x04"):
        return True
    return False


def _sanitize_text(s: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç NUL –∏ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã, –æ–±—Ä–µ–∑–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã."""
    if not s:
        return ""
    # —É–¥–∞–ª–∏—Ç—å NUL
    s = s.replace("\x00", "")
    # —É–¥–∞–ª–∏—Ç—å –ø—Ä–æ—á–∏–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ, –∫—Ä–æ–º–µ \t\n\r
    s = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F]", "", s)
    return s.strip()


def _split_lines(content: bytes) -> List[str]:
    # –ï—Å–ª–∏ —ç—Ç–æ –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª (xlsx/zip) ‚Äî –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –≤—ã—à–µ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ–º
    text = content.decode("utf-8", errors="ignore")
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = text.replace("\r", "")
    # –æ—á–∏—â–∞–µ–º —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ NUL
    text = _sanitize_text(text)
    lines = [l.strip() for l in text.split("\n")]
    # –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    return [l for l in lines if l]


def _extract_username(link_or_username: str | None) -> str | None:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å—Ç—ã–π username –±–µ–∑ @ –∏ —Å—Å—ã–ª–æ–∫ t.me, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ."""
    if not link_or_username:
        return None
    s = link_or_username.strip()
    if s.startswith("http://") or s.startswith("https://"):
        if "t.me/" in s:
            try:
                part = s.split("t.me/")[1]
                s = part.split("/")[0].split("?")[0]
            except Exception:
                pass
    if s.startswith("@"):
        s = s[1:]
    return s or None


async def _resolve_real_title(bot, link_or_username: str | None) -> str | None:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π title –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ Bot API –ø–æ username/—Å—Å—ã–ª–∫–µ."""
    try:
        username = _extract_username(link_or_username or "")
        if not username:
            return None
        # –î–ª—è Bot API –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å '@username'
        chat_id = username if username.startswith("@") else f"@{username}"
        chat = await bot.get_chat(chat_id)
        title = getattr(chat, "title", None)
        return title or None
    except Exception:
        return None


def _parse_channel_line(line: str) -> Tuple[str | None, str | None, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (channel_username, invite_link, title) –∏–∑ —Å—Ç—Ä–æ–∫–∏.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
    - –ø—Ä–æ—Å—Ç–æ–π: "@username" | "https://t.me/username" | "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"
    - CSV: "username,title,link,status,description,is_private,..."
    """
    raw = line.strip()
    if not raw:
        return None, None, ""

    # –ü–æ–ø—ã—Ç–∫–∞ CSV: split –ø–æ –∑–∞–ø—è—Ç—ã–º (–ø—Ä–æ—Å—Ç–∞—è, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫)
    if "," in raw:
        parts = [p.strip() for p in raw.split(",")]
        # –æ–∂–∏–¥–∞–µ–º –º–∏–Ω–∏–º—É–º 3 –ø–æ–ª—è: username, title, link
        if len(parts) >= 3:
            csv_username = parts[0].lstrip("@") or None
            csv_title = parts[1] or ""
            csv_link = parts[2] or None
            # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º username –∏–∑ —Å—Å—ã–ª–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if (not csv_username) and (csv_link and "t.me/" in csv_link):
                try:
                    part = csv_link.split("t.me/")[1]
                    csv_username = part.split("/")[0].split("?")[0]
                except Exception:
                    pass
            return (csv_username or None), (csv_link or None), csv_title

    # –ü—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç
    if raw.startswith("@"):
        username = raw.lstrip("@").split()[0]
        return username, None, username
    if "t.me/" in raw:
        # https://t.me/username or http://t.me/username/123
        try:
            part = raw.split("t.me/")[1]
            username = part.split("/")[0].split("?")[0]
            username = username.replace("+", "")  # –¥–ª—è joinchat —Å—Å—ã–ª–∫–∏ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –ø—Ä–∏–≥–ª–∞—à–∞—é—â—É—é —Å—Å—ã–ª–∫—É
        except Exception:
            username = None
        return username or None, raw, username or raw
    # –ò–Ω–∞—á–µ —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    return None, None, raw


@router.message(F.text == "üì• –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª—ã")
async def start_bulk_channels(message: Message, state: FSMContext):
    if not await UserService.cheek_user_permissions_static(message.from_user.id, "admin"):
        await message.answer("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤. –§—É–Ω–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º.")
        return
    await message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ .txt —Ñ–∞–π–ª —Å –∫–∞–Ω–∞–ª–∞–º–∏ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî @username, —Å—Å—ã–ª–∫–∞ t.me/... –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞).")
    await state.set_state(BulkImportChannels.waiting_for_file)


@router.message(BulkImportChannels.waiting_for_file, F.document)
async def handle_bulk_channels_file(message: Message, state: FSMContext):
    if not await UserService.cheek_user_permissions_static(message.from_user.id, "admin"):
        await message.answer("‚ö†Ô∏è –ù–µ—Ç –ø—Ä–∞–≤.")
        return
    doc = message.document
    if not doc or (doc.file_name and not (doc.file_name.lower().endswith(".txt") or doc.file_name.lower().endswith(".csv"))):
        await message.answer("–ó–∞–≥—Ä—É–∑–∏—Ç–µ .txt –∏–ª–∏ .csv —Ñ–∞–π–ª.")
        return
    buf = io.BytesIO()
    try:
        await message.bot.download(doc.file_id, destination=buf)
        buf.seek(0)
        data = buf.getvalue()
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã (—á–∞—Å—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–∏—Å—ã–ª–∞—é—Ç .xlsx)
        if _is_probably_binary(data):
            await message.answer("–§–∞–π–ª –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, .xlsx/.docx). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ –ø—Ä–æ—Å—Ç–æ–π .txt —Ñ–∞–π–ª, –≥–¥–µ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî @username, —Å—Å—ã–ª–∫–∞ t.me/... –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞.")
            return
        lines = _split_lines(data)
    except Exception as e:
        main_logger.error(f"bulk channels download error: {e}")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª.")
        return

    created = 0
    skipped = 0
    async with get_atomic_db() as db:
        for line in lines:
            username, invite, title = _parse_channel_line(line)
            # –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—è
            if username:
                username = _sanitize_text(username)
            if invite:
                invite = _sanitize_text(invite)
            title = _sanitize_text(title)
            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π title –ø–æ username/—Å—Å—ã–ª–∫–µ
            if (username or invite) and not title:
                real_title = await _resolve_real_title(message.bot, username or invite)
                if real_title:
                    title = _sanitize_text(real_title)
            elif (username or invite):
                real_title = await _resolve_real_title(message.bot, username or invite)
                if real_title:
                    title = _sanitize_text(real_title)
            # –ë–∞–∑–æ–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            if not title:
                skipped += 1
                continue
            if len(title) > 200:
                # –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–ª–∏–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ –º—É—Å–æ—Ä –∏–∑ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ
                skipped += 1
                continue
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è
            exists = None
            if username:
                exists = await db.channel.get_channel_by_filter(channel_username=username)
            if not exists:
                exists = await db.channel.get_channel_by_filter(title=title)
            if exists:
                skipped += 1
                continue
            try:
                await db.channel.create_channel(AddChannel(
                    channel_username=username,
                    title=title,
                    invite_link=invite,
                    status="disabled",
                    description=None,
                    is_private=False,
                    last_parsed_message_id=None,
                    last_checked=None,
                ))
                created += 1
            except Exception as e:
                main_logger.error(f"create channel failed for line '{line}': {e}")
                skipped += 1

    await state.clear()
    await message.answer(f"–ì–æ—Ç–æ–≤–æ. –î–æ–±–∞–≤–ª–µ–Ω–æ –∫–∞–Ω–∞–ª–æ–≤: {created}. –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}.")


@router.message(F.text == "üì• –î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞")
async def start_bulk_keywords(message: Message, state: FSMContext):
    if not await UserService.cheek_user_permissions_static(message.from_user.id, "admin"):
        await message.answer("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤. –§—É–Ω–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º.")
        return
    await message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ .txt —Ñ–∞–π–ª —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –æ–¥–Ω–æ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞/—Ä–µ–≥—ç–∫—Å–ø).")
    await state.set_state(BulkImportKeywords.waiting_for_file)


@router.message(BulkImportKeywords.waiting_for_file, F.document)
async def handle_bulk_keywords_file(message: Message, state: FSMContext):
    if not await UserService.cheek_user_permissions_static(message.from_user.id, "admin"):
        await message.answer("‚ö†Ô∏è –ù–µ—Ç –ø—Ä–∞–≤.")
        return
    doc = message.document
    if not doc or (doc.file_name and not doc.file_name.lower().endswith(".txt")):
        await message.answer("–ó–∞–≥—Ä—É–∑–∏—Ç–µ .txt —Ñ–∞–π–ª.")
        return
    buf = io.BytesIO()
    try:
        await message.bot.download(doc.file_id, destination=buf)
        buf.seek(0)
        lines = _split_lines(buf.getvalue())
    except Exception as e:
        main_logger.error(f"bulk keywords download error: {e}")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª.")
        return

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤ lower –¥–ª—è –¥–µ-–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
    existing_lower = set()
    async with get_atomic_db() as db:
        all_kw = await db.keywords.get_all_keywords()
        existing_lower = { (k.text or "").strip().lower() for k in all_kw }

    to_create: List[KeyWordCreateSchema] = []
    for line in lines:
        norm = line.strip()
        if not norm:
            continue
        if norm.lower() in existing_lower:
            continue
        to_create.append(KeyWordCreateSchema(text=cast(str, norm), type=KeywordType.WORD, is_active=True))
        existing_lower.add(norm.lower())

    created = 0
    async with get_atomic_db() as db:
        for payload in to_create:
            try:
                await db.keywords.create_keyword(payload)
                created += 1
            except Exception as e:
                main_logger.error(f"create keyword failed for '{payload.text}': {e}")

    await state.clear()
    await message.answer(f"–ì–æ—Ç–æ–≤–æ. –î–æ–±–∞–≤–ª–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {created}. –ü—Ä–æ–ø—É—â–µ–Ω–æ: {len(lines) - created}.")
